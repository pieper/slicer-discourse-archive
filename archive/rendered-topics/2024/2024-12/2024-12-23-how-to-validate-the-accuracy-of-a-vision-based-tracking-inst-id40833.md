# How to validate the accuracy of a vision-based tracking instrument in 3D Slicer navigation?

**Topic ID**: 40833
**Date**: 2024-12-23
**URL**: https://discourse.slicer.org/t/how-to-validate-the-accuracy-of-a-vision-based-tracking-instrument-in-3d-slicer-navigation/40833

---

## Post #1 by @wenlin_x (2024-12-23 08:51 UTC)

<p>Hi everyone,</p>
<p>I’m developing a vision-based tracking instrument and would like to use it for navigation in 3D Slicer. So far, I have completed the following steps:</p>
<ol>
<li>Installed the “IGT” module in 3D Slicer.</li>
<li>Created a <code>needle model</code> and performed registration for the needle.</li>
<li>While testing on a human model, the navigation appears accurate based on visual inspection.</li>
</ol>
<p>My questions are:</p>
<ol>
<li><strong>What should I pay attention to during this process to ensure tracking accuracy?</strong></li>
<li><strong>How can I scientifically validate the localization and navigation accuracy of my instrument?</strong></li>
</ol>
<ul>
<li>For instance, are there recommended tools, methods, or evaluation standards for this?</li>
<li>Should I use a phantom (calibration object) or known landmarks to measure errors?</li>
</ul>
<p>Any advice on how to evaluate the performance of my tracking instrument would be greatly appreciated!</p>
<p>Thank you in advance for your help!</p>

---
