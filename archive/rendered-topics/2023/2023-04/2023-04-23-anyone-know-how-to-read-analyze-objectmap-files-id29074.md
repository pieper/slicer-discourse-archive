# Anyone know how to read Analyze ObjectMap files?

**Topic ID**: 29074
**Date**: 2023-04-23
**URL**: https://discourse.slicer.org/t/anyone-know-how-to-read-analyze-objectmap-files/29074

---

## Post #1 by @pieper (2023-04-23 21:28 UTC)

<p><a class="mention" href="/u/ron">@Ron</a> Alkalay and I are trying to work with some segmentations generated by <a href="https://analyzedirect.com/">Analyze</a>.  He was able to export it in .hdr/.img format, but the pixel to world (ijkToRAS) is identity so the data doesn’t match the CT as shown below.</p>
<p>Anonymized data is here: <a href="https://drive.google.com/drive/folders/1bgnk8msRqM_6Vz5OSywa-EEQLuRAx5oz?usp=sharing" class="inline-onebox">object-map-debug - Google Drive</a> in case anyone want’s to give it a try or knows any conventions about how it’s encoded.</p>
<p><div class="lightbox-wrapper"><a class="lightbox" href="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/6/6/66222f5044eaf5ced04f15c3d30d4063580f9e19.jpeg" data-download-href="/uploads/short-url/ezvWrragaPwlmlLyGZsPeRehclr.jpeg?dl=1" title="image"><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/6/66222f5044eaf5ced04f15c3d30d4063580f9e19_2_690x432.jpeg" alt="image" data-base62-sha1="ezvWrragaPwlmlLyGZsPeRehclr" width="690" height="432" srcset="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/6/66222f5044eaf5ced04f15c3d30d4063580f9e19_2_690x432.jpeg, https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/6/6/66222f5044eaf5ced04f15c3d30d4063580f9e19.jpeg 1.5x, https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/6/6/66222f5044eaf5ced04f15c3d30d4063580f9e19.jpeg 2x" data-dominant-color="9693BE"><div class="meta">
<svg class="fa d-icon d-icon-far-image svg-icon" aria-hidden="true"><use href="#far-image"></use></svg><span class="filename">image</span><span class="informations">1003×629 147 KB</span><svg class="fa d-icon d-icon-discourse-expand svg-icon" aria-hidden="true"><use href="#discourse-expand"></use></svg>
</div></a></div></p>
<p><div class="lightbox-wrapper"><a class="lightbox" href="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/6/4/641d9c25cd5d1f5a86d2ed61fdec51bc65ac93ad.jpeg" data-download-href="/uploads/short-url/ehFbxgFjOBBzxIVvyxfCUsgd1zn.jpeg?dl=1" title="image"><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/4/641d9c25cd5d1f5a86d2ed61fdec51bc65ac93ad_2_690x319.jpeg" alt="image" data-base62-sha1="ehFbxgFjOBBzxIVvyxfCUsgd1zn" width="690" height="319" srcset="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/4/641d9c25cd5d1f5a86d2ed61fdec51bc65ac93ad_2_690x319.jpeg, https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/4/641d9c25cd5d1f5a86d2ed61fdec51bc65ac93ad_2_1035x478.jpeg 1.5x, https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/6/4/641d9c25cd5d1f5a86d2ed61fdec51bc65ac93ad_2_1380x638.jpeg 2x" data-dominant-color="3B3B44"><div class="meta">
<svg class="fa d-icon d-icon-far-image svg-icon" aria-hidden="true"><use href="#far-image"></use></svg><span class="filename">image</span><span class="informations">1439×667 141 KB</span><svg class="fa d-icon d-icon-discourse-expand svg-icon" aria-hidden="true"><use href="#discourse-expand"></use></svg>
</div></a></div></p>
<p>I also tried this code: <a href="https://github.com/pkostandy/objparser/blob/master/objparser.py" class="inline-onebox">objparser/objparser.py at master · pkostandy/objparser · GitHub</a></p>
<p>but the headers don’t seem to have any geometry information either.</p>
<p>He has over a hundred of these, and worst case would be to just line it up manually somehow, or maybe it could be semi-automated, but we’d rather figure out how to either read this data or export it another way from Analyze where it looks like this:</p>
<p><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/2/f/2f9df7c69939fd26ef1caff5283dcc621b7a3a96.jpeg" alt="image" data-base62-sha1="6NeSUI04HxyHvPMJlTCDSkFen6C" width="483" height="315"></p>
<p><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/d/d/dd510e3fa2313fc6fe02e70421ba5b19779dd429.jpeg" alt="image" data-base62-sha1="vzRbhhONnFzKiQxWQsQuQbo9HUl" width="367" height="308"></p>

---

## Post #2 by @mau_igna_06 (2023-04-23 22:12 UTC)

<p>Maybe you could use the exported CT data from Analize (e.g. nrrd if possible) to make a Elastix registration (or any other image registration algorithm) with the same CT image imported from the DICOM data to Slicer</p>
<p>Hope it helps</p>

---

## Post #3 by @muratmaga (2023-04-23 22:24 UTC)

<p>I haven’t touched analyze since I switched to Slicer a decade ago. but from what I recall, during import there was an option to spacify “slice orientation (or ordering perhaps)”, with options like transverse, coronal, sagittal. So basically you can import the same image stack in different orientaitons, and I believe this wasn’t written to the file header. At least this was with the microCT scan sequences we had. Don’t know about DICOM or clinical images.</p>
<p>Try flipping in all cardinal directions, and see if it lines up. From the picture, the segmentation seems upside down (IS axis) and facing opposite direction (AP) with respect to the volume. So perhaps it is an easy flip of axes.</p>

---

## Post #4 by @blezek (2023-04-24 19:51 UTC)

<p>Hey <a class="mention" href="/u/pieper">@pieper</a> !</p>
<p>Analyze Object Maps don’t contain any orientation nor spacing information, they are designed to be paired up with an original volume.  I believe they are stored in <code>RPI</code> orientation, but using Analyze’s left-handed coordinate system.  If you flip the object map in Y or do the coordinate system conversion to map from a left-handed, <code>RPI</code> orientation into (what looks to be) right-handed <code>LPS</code> coordinate system, it should line up correctly.</p>
<p>Once upon a time, ITK read the ObjectMap format (I couldn’t attach code <img src="https://emoji.discourse-cdn.com/twitter/frowning_face.png?v=12" title=":frowning_face:" class="emoji" alt=":frowning_face:" loading="lazy" width="20" height="20"> ).  Though the ITK Doxygen site references the code (see <a href="https://itk.org/Doxygen50/html/classitk_1_1AnalyzeObjectLabelMapImageIO.html" rel="noopener nofollow ugc">here</a>, <a href="https://itk.org/Doxygen50/html/dir_f5f8fa485087d9ec419750b9df6227de.html" rel="noopener nofollow ugc">here</a>, and <a href="https://itk.org/Doxygen50/html/dir_6733826ecb0ee899e8e47cc177f7ace4.html" rel="noopener nofollow ugc">here</a>, I’m not sure if this is just doxygen <em>cruft</em> or not.</p>
<p><strong>Edit:</strong> link rot got to Hans’ <a href="https://doi.org/10.54294/w2jytv" rel="noopener nofollow ugc">ITK Journal article</a>, not sure where the original code might be found.  I have a copy if you’d like to DM me.</p>
<p>This is a short snippit of how to read ObjectMap files:</p>
<pre><code class="lang-auto">        // Try to load the objectmap
        typedef signed short PixelType;
        typedef itk::Image&lt;PixelType, 3&gt; ImageType;
        typedef itk::Image&lt;itk::RGBPixel&lt;PixelType&gt;, 3&gt; RGBImageType;
        typedef itk::ImageFileReader&lt;ImageType&gt; ReaderType;
        typedef itk::AnalyzeObjectMap&lt;ImageType, RGBImageType&gt; ObjectMapType;

        itk::AnalyzeObjectLabelMapImageIOFactory::Pointer metaFactory = itk::AnalyzeObjectLabelMapImageIOFactory::New();
        itk::ObjectFactoryBase::RegisterFactory(metaFactory);

        logger-&gt;debug("Starting to read");
        ReaderType::Pointer Reader = ReaderType::New();
        Reader-&gt;SetFileName(this-&gt;mFilename.c_str());


...

        ObjectMapType::Pointer itkObjectMap = ObjectMapType::New();
        itkObjectMap-&gt;ImageToObjectMap(Reader-&gt;GetOutput());

...
        // get info from the first object
        itk::AnalyzeObjectEntry::Pointer original = itkObjectMap-&gt;GetObjectEntry(0);

...

        // Loop over the ITK objects and create our guys
        for (int i = 0; i &lt; itkObjectMap-&gt;GetNumberOfObjects(); i++) {
            ObjectEntry e;
            e.Name = itkObjectMap-&gt;GetObjectEntry(i)-&gt;GetName();
            e.Red = itkObjectMap-&gt;GetObjectEntry(i)-&gt;GetEndRed();
            e.Green = itkObjectMap-&gt;GetObjectEntry(i)-&gt;GetEndGreen();
            e.Blue = itkObjectMap-&gt;GetObjectEntry(i)-&gt;GetEndBlue();
            e.Alpha = itkObjectMap-&gt;GetObjectEntry(i)-&gt;GetBlendFactor();
        }

</code></pre>

---

## Post #5 by @pieper (2023-04-24 20:17 UTC)

<p>Super helpful <a class="mention" href="/u/blezek">@blezek</a> - let me chew on this a bit!</p>

---

## Post #6 by @issakomi (2023-04-25 07:13 UTC)

<p>There are some options in ITK’s Nifti IO to control <a href="https://github.com/InsightSoftwareConsortium/ITK/blob/7a89717c1a517a5d7d354c4dfcca8e0871817d2f/Modules/IO/NIFTI/include/itkNiftiImageIO.h#L42" rel="noopener nofollow ugc">Analyze75Flavor</a>, specially the axis (AFAIK).<br>
Might be useful in addition to the post above (perhaps the behavior of Nifti IO has changed since 2009).</p>
<pre><code class="lang-auto">#include &lt;itkImage.h&gt;
#include &lt;itkImageFileReader.h&gt;
#include &lt;itkImageFileWriter.h&gt;
#include &lt;itkNiftiImageIO.h&gt;
#include &lt;sstream&gt;
#include &lt;iostream&gt;

int main(int argc, char ** argv)
{
	if (argc &lt; 4)
	{
		std::cout &lt;&lt;
			"3 arguments are required\n"
			"    input file name (Analyze),\n"
			"    output file name (e.g. out.nrrd)\n"
			"    Analyze75Flavor (0 - 4)"
				&lt;&lt; std::endl;
		return 0;
	}

	using ImageTypeUC = itk::Image&lt;unsigned char, 3&gt;;

	std::stringstream ss(argv[3]);
	int argv3;
	ss &gt;&gt; argv3;

	itk::NiftiImageIO::Pointer io = itk::NiftiImageIO::New();
	itk::ImageFileReader&lt;ImageTypeUC&gt;::Pointer reader =	itk::ImageFileReader&lt;ImageTypeUC&gt;::New();
	io-&gt;SetLegacyAnalyze75Mode(static_cast&lt;itk::NiftiImageIOEnums::Analyze75Flavor&gt;(argv3));
	const int analyse75Flavor = static_cast&lt;int&gt;(io-&gt;GetLegacyAnalyze75Mode());
	switch (analyse75Flavor)
	{
	case 0:
		std::cout &lt;&lt; "Analyze75Flavor::AnalyzeReject" &lt;&lt; std::endl;
		break;
	case 1:
		std::cout &lt;&lt; "Analyze75Flavor::AnalyzeITK4Warning" &lt;&lt; std::endl;
		break;
	case 2:
		std::cout &lt;&lt; "Analyze75Flavor::AnalyzeSPM" &lt;&lt; std::endl;
		break;
	case 3:
		std::cout &lt;&lt; "Analyze75Flavor::AnalyzeFSL" &lt;&lt; std::endl;
		break;
	case 4:
		std::cout &lt;&lt; "Analyze75Flavor::AnalyzeITK4" &lt;&lt; std::endl;
		break;
	default:
		std::cout &lt;&lt; "Analyze75Flavor unknown" &lt;&lt; std::endl;
		break;
	}
	reader-&gt;SetImageIO(io);
	reader-&gt;SetFileName(argv[1]);
	try
	{
		reader-&gt;Update();
	}
	catch (const itk::ExceptionObject &amp; e)
	{
		std::cout &lt;&lt; e.GetDescription() &lt;&lt; std::endl;
		return 1;
	}
	
	itk::ImageFileWriter&lt;ImageTypeUC&gt;::Pointer writer =	itk::ImageFileWriter&lt;ImageTypeUC&gt;::New();
	writer-&gt;SetFileName(argv[2]);
	try
	{
		writer-&gt;SetInput(reader-&gt;GetOutput());
		writer-&gt;Update();
	}
	catch (const itk::ExceptionObject &amp; e)
	{
		std::cout &lt;&lt; e.GetDescription() &lt;&lt; std::endl;
		return 1;
	}

	return 0;
}
</code></pre>

---

## Post #7 by @pieper (2023-04-27 14:21 UTC)

<p>Thanks very much for the advice everyone.  <img src="https://emoji.discourse-cdn.com/twitter/+1.png?v=12" title=":+1:" class="emoji" alt=":+1:" loading="lazy" width="20" height="20"></p>
<p>Based on the clues given here, we were able to go back to Analyze and export both the CT image and the object map as Analyze 7.5 .hdr/.img files with the same pixel dimensions.  Loading those in Slicer, the A/P direction was flipped and the label volume had identity IJKToRAS transform.  Flipping in A/P and copying over the matrix with the python code below gave this image:</p>
<p><div class="lightbox-wrapper"><a class="lightbox" href="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/c/d/cd4770c4fb624686b94a71ceff9b834fe74b1094.jpeg" data-download-href="/uploads/short-url/thYWp7EtJFqA2AZ11IhSq7lzkuE.jpeg?dl=1" title="image"><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/c/d/cd4770c4fb624686b94a71ceff9b834fe74b1094_2_617x500.jpeg" alt="image" data-base62-sha1="thYWp7EtJFqA2AZ11IhSq7lzkuE" width="617" height="500" srcset="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/c/d/cd4770c4fb624686b94a71ceff9b834fe74b1094_2_617x500.jpeg, https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/c/d/cd4770c4fb624686b94a71ceff9b834fe74b1094_2_925x750.jpeg 1.5x, https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/c/d/cd4770c4fb624686b94a71ceff9b834fe74b1094_2_1234x1000.jpeg 2x" data-dominant-color="48494E"><div class="meta">
<svg class="fa d-icon d-icon-far-image svg-icon" aria-hidden="true"><use href="#far-image"></use></svg><span class="filename">image</span><span class="informations">1439×1166 182 KB</span><svg class="fa d-icon d-icon-discourse-expand svg-icon" aria-hidden="true"><use href="#discourse-expand"></use></svg>
</div></a></div></p>
<pre><code class="lang-auto">ctPath = "/opt/data/SlicerSpine/Muscle data/Muscle data/Muscle data/E15558S301.hdr"
objPath = "/opt/data/SlicerSpine/Muscle data/Muscle data/15558_ObjectMap.hdr"

ctNode = slicer.util.loadVolume(ctPath)
labelNode = slicer.util.loadLabelVolume(objPath)

ijkToRAS = vtk.vtkMatrix4x4()
ctNode.GetIJKToRASMatrix(ijkToRAS)
ijkToRAS.SetElement(1,1, -1 * ijkToRAS.GetElement(1,1))
ctNode.SetIJKToRASMatrix(ijkToRAS)
labelNode.SetIJKToRASMatrix(ijkToRAS)
</code></pre>
<p>Converting to a segmentation and using Fill between Slices gave this result, which looks promising.  We have over 100 of these so we hope to be able to train a MONAI Label model to segment these muscles.</p>
<p><div class="lightbox-wrapper"><a class="lightbox" href="https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/0/2/024dd4ee68ee3607cd44a6f186ca9005a2e0cc41.jpeg" data-download-href="/uploads/short-url/knHWkI39Um4Uxhuhyzh5HUatlD.jpeg?dl=1" title="image"><img src="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/0/2/024dd4ee68ee3607cd44a6f186ca9005a2e0cc41_2_626x500.jpeg" alt="image" data-base62-sha1="knHWkI39Um4Uxhuhyzh5HUatlD" width="626" height="500" srcset="https://us1.discourse-cdn.com/flex002/uploads/slicer/optimized/3X/0/2/024dd4ee68ee3607cd44a6f186ca9005a2e0cc41_2_626x500.jpeg, https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/0/2/024dd4ee68ee3607cd44a6f186ca9005a2e0cc41.jpeg 1.5x, https://us1.discourse-cdn.com/flex002/uploads/slicer/original/3X/0/2/024dd4ee68ee3607cd44a6f186ca9005a2e0cc41.jpeg 2x" data-dominant-color="7C7F8E"><div class="meta">
<svg class="fa d-icon d-icon-far-image svg-icon" aria-hidden="true"><use href="#far-image"></use></svg><span class="filename">image</span><span class="informations">726×579 119 KB</span><svg class="fa d-icon d-icon-discourse-expand svg-icon" aria-hidden="true"><use href="#discourse-expand"></use></svg>
</div></a></div></p>
<p>I’ll also note that while the .hrd / .img files worked in the end, it looked like the same pixel data could be extracted using the objparser python code, but the header doesn’t include the pixel geometry so you need the .hdr of the source image for the object map to be of use (probably the ITK code could also work to get the pixels, but I didn’t have a chance to try).  The object map file does include all the label identifiers so ultimately I will be using that information to assign the proper names to the muscles.</p>

---
